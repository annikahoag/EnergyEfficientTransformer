  Project was inspired by the paper "TransNAS-TSAD: Harnessing Transformers for Multi-Objective Neural Architecture Search in Time Series Anomaly Detection" by Ijaz Ul Haq, Byung Suk Lee, and Donna M. Rizzo. The folder titled "TransNAS-TSAD" is from this work, with the modification of adding a third objective to their original multi-objective algorithm (MOOA) which was minimizing the amount of power draw from the GPU. Upon adding this to the original code base, we found that the relationship between GPU power draw, parameter count of the model, and the F1 score (representing the accuracy of anomaly detection) appeared to be uncorrelated. We also attempted to modify the MOOA to use CMA-ES and create a fitness function based on the accuracy values and GPU power draw readings, which provided similar results.
  In order to figure out the cause of this, we changed the task of the project to a standard image classification task using the CIFAR-10 dataset, the code for which is in the "ImageClassification folder". We handcrafted a base convolutional neural network (CNN) and changed the parameters of the model using configuration files. We then reported the GPU power draw of training that model, the parameter count, and the validation accuracy of the model and compared those. Once again, the results showed that there was no correlation among these metrics, which led us to hypothesize that the expected correlation (increased parameter count leading to increase accuracy with increased power draw) will only appear with larger scale models and larger scale hardware. Essentially, the known expected relationship among parameter count, accuracy of the task, and GPU power draw will only be seen when training with very high parameter count on stronger hardware than we have access to. So for now this work remains unpublished, but could be extended to prove this concept of there being a minimum level of parameter count and hardware to show an impact on energy usage. 

  To run the TransNAS-TSAD inspired code, set up the virtual environment in that folder and run the file "demo_transnas_tsad.py". The F1 score, parameter count, and GPU power draw (total and average) will be saved to a database called "results.db". From there you can graph the results using the functions in "view_results.py".
